{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps 1&2 :** Download the DOS/Windows for Dec. zip file, extract file.\n",
    "+ Visit https://www.census.gov/data/datasets/2017/demo/cps/cps-basic-2017.html to download the file.\n",
    "+ The downloaded file in *dec17pub.dat*, available in the project root folder.\n",
    "+ Load essential pyspark libraries and initialize spark context and session.\n",
    "+ Display spark engine version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spark version is : 3.5.1\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "spark = SparkSession.builder.appName('Data Engineer - Take Home Project').getOrCreate()\n",
    "print(f'The spark version is : {spark.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3 :** Showing a sample of *DOS/Windows for Dec* zip file\n",
    "+ Open the file and map columns from each line to variables\n",
    "+ Add each mapped line columns to a List object\n",
    "+ Create a dataframe df_Master from the List\n",
    "+ Display sample records from df_Master "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to hold records from file\n",
    "rows = list()\n",
    "\n",
    "# Open the file for read operation\n",
    "with open('dec17pub.dat','r') as file:\n",
    "    \n",
    "    # Read each line and map the columns to variables\n",
    "    for line in file:\n",
    "        full_household_identifier = line[:15]\n",
    "        time_of_interview = line[17:21] + '/' + line[15:17]\n",
    "        final_outcome_of_survey = line[23:26]\n",
    "        type_of_housing_unit = line[31:32]\n",
    "        household_type = line[61:62]\n",
    "        household_has_telephone = line[33:34]\n",
    "        household_can_access_telephone = line[35:36]\n",
    "        is_telephone_interview_acceptable = line[37:38]\n",
    "        type_of_interview = line[65:66]\n",
    "        family_income_range = line[39:40]\n",
    "        division_location =  line[90:91]\n",
    "        race =  line[138:140]\n",
    "\n",
    "        #Create a record from above variables and add record to a List\n",
    "        item = (full_household_identifier,\n",
    "                time_of_interview,\n",
    "                final_outcome_of_survey,\n",
    "                type_of_housing_unit,\n",
    "                household_type,\n",
    "                household_has_telephone,\n",
    "                household_can_access_telephone,\n",
    "                is_telephone_interview_acceptable,\n",
    "                type_of_interview,\n",
    "                family_income_range,    \n",
    "                division_location,\n",
    "                race)\n",
    "        rows.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----------------+----------------------------+-------------------------+-------------------+----------------------------+-----------------------------------+--------------------------------------+----------------------+------------------------+----------------------+---------+\n",
      "|full_household_identifier|time_of_interview|final_outcome_of_survey_code|type_of_housing_unit_code|household_type_code|household_has_telephone_code|household_can_access_telephone_code|is_telephone_interview_acceptable_code|type_of_interview_code|family_income_range_code|division_location_code|race_code|\n",
      "+-------------------------+-----------------+----------------------------+-------------------------+-------------------+----------------------------+-----------------------------------+--------------------------------------+----------------------+------------------------+----------------------+---------+\n",
      "|000004795110719          |2017/12          |201                         |1                        |1                  |1                           |1                                  |1                                     |2                     |9                       |6                     | 1       |\n",
      "|000004795110719          |2017/12          |201                         |1                        |1                  |1                           |1                                  |1                                     |2                     |9                       |6                     | 1       |\n",
      "|000071691004941          |2017/12          |201                         |1                        |1                  |1                           |1                                  |1                                     |1                     |1                       |6                     | 1       |\n",
      "|000071691004941          |2017/12          |201                         |1                        |1                  |1                           |1                                  |1                                     |1                     |1                       |6                     | 1       |\n",
      "|000071691004941          |2017/12          |201                         |1                        |1                  |1                           |1                                  |1                                     |1                     |1                       |6                     | 1       |\n",
      "+-------------------------+-----------------+----------------------------+-------------------------+-------------------+----------------------------+-----------------------------------+--------------------------------------+----------------------+------------------------+----------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe and display sample records\n",
    "from schema import master_schema\n",
    "df_master = spark.createDataFrame(rows, master_schema)\n",
    "df_master.show(5, truncate= False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4 :** Answer to Questions 1 - 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **1.** What is the count of responders per family income range (show all)?\n",
    "+ Create dataframe **df_family_income** to decode Family Income Range\n",
    "+ Select only required fields from *df_Master* for a fast runtime\n",
    "+ Join the dataframes and generate the result\n",
    "+ Please note - *there are null values in the outcome of this join based on findings from deeper analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load schema and data for family income data structure\n",
    "from schema import family_income_range_schema\n",
    "from data import family_income_range_data\n",
    "\n",
    "df_family_income = spark.createDataFrame(family_income_range_data, family_income_range_schema)\n",
    "\n",
    "#df_family_income.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the join and run the analysis\n",
    "Question_1 = df_master.select('family_income_range_code')\\\n",
    "    .join(df_family_income, df_master.family_income_range_code == df_family_income.family_code, 'left')\\\n",
    "        .groupBy('family_income_range')\\\n",
    "            .count()\\\n",
    "                .orderBy('family_income_range', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|FAMILY_INCOME_RANGE|COUNT_OF_RESPONDERS|\n",
      "+-------------------+-------------------+\n",
      "|LESS THAN $5,000   |33315              |\n",
      "|7,500 TO 9,999     |15719              |\n",
      "|5,000 TO 7,499     |11596              |\n",
      "|30,000 TO 34,      |6743               |\n",
      "|25,000 TO 29,999   |5803               |\n",
      "|20,000 TO 24,999   |6312               |\n",
      "|15,000 TO 19,999   |20222              |\n",
      "|12,00 TO 14,999    |20408              |\n",
      "|10,000 TO 12,999   |19718              |\n",
      "|NULL               |6620               |\n",
      "+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Format and display the result for Question one\n",
    "Question_1.toDF('FAMILY_INCOME_RANGE','COUNT_OF_RESPONDERS').show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.** What is the count of responders per geographical division/location and race (show top 10)?\n",
    "+ Create dataframe **df_geo_location** and **df_race** to decode Location and Race\n",
    "+ Select only required fields from *df_Master* for fast execution time \n",
    "+ Join the dataframes and generate the result\n",
    "+ Please note - *there are null values in the outcome of this join based on findings from deeper analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema import division_location_schema, race_schema\n",
    "from data import division_location_data, race_data\n",
    "\n",
    "df_geo_location = spark.createDataFrame(division_location_data, division_location_schema)\n",
    "df_race = spark.createDataFrame(race_data, race_schema)\n",
    "\n",
    "#df_geo_location.show(3,truncate=False)\n",
    "#df_race.show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the join and run the analysis\n",
    "Question_2 = df_master.select('division_location_code','race_code')\\\n",
    "    .join(df_geo_location, df_master.division_location_code == df_geo_location.geo_code, 'left')\\\n",
    "        .join(df_race, df_master.race_code == df_race.race_code, 'left')\\\n",
    "            .groupBy('division_location','race')\\\n",
    "                .count()\\\n",
    "                    .orderBy('count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-------------------+\n",
      "| DIVISION_LOCATION|    RACE|COUNT_OF_RESPONDERS|\n",
      "+------------------+--------+-------------------+\n",
      "|    SOUTH ATLANTIC|    NULL|              27609|\n",
      "|           PACIFIC|    NULL|              20659|\n",
      "|          MOUNTAIN|    NULL|              18470|\n",
      "|WEST SOUTH CENTRAL|    NULL|              16498|\n",
      "|EAST NORTH CENTRAL|    NULL|              15296|\n",
      "|WEST NORTH CENTRAL|    NULL|              13052|\n",
      "|   MIDDLE ATLANTIC|    NULL|              12756|\n",
      "|       NEW ENGLAND|    NULL|              11281|\n",
      "|EAST SOUTH CENTRAL|    NULL|              10345|\n",
      "|           PACIFIC|Asian-HP|                 70|\n",
      "+------------------+--------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Format and display Top 10 only\n",
    "Question_2.toDF('DIVISION_LOCATION', 'RACE', 'COUNT_OF_RESPONDERS').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.** How many responders do not have telephone in their house, but can access a telephone elsewhere and telephone interview is accepted?\n",
    "+ Create dataframes **df_bool** to decode phone data related columns YES - (1) or NO - (2)\n",
    "+ Select only required fields from *df_Master* for fast execution time \n",
    "+ Join the dataframes and generate the result\n",
    "+ Observation - data values for '*Is telephone interview acceptable*' shows values (0,1) instaed of (1,2) as expected. \n",
    "+ Decoding will never return NO as values for the observation above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to Question (3) is : 635\n"
     ]
    }
   ],
   "source": [
    "Question_3 = df_master.where(\n",
    "    (col('household_has_telephone_code') == lit('2')) &\n",
    "    (col('household_can_access_telephone_code')  == lit('1')) &\n",
    "    (col('is_telephone_interview_acceptable_code') == lit('1'))\n",
    ").count()\n",
    "\n",
    "print(f'The answer to Question (3) is : {Question_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema import bool_table_schema, has_tel_schema, can_access_tel_schema, tel_interview_acceptable_schema\n",
    "from data import bool_table_data\n",
    "\n",
    "df_bool = spark.createDataFrame(bool_table_data, bool_table_schema)\n",
    "#df_bool.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_3 = df_master\\\n",
    "    .select(\n",
    "        'household_has_telephone_code',\n",
    "        'household_can_access_telephone_code',\n",
    "        'is_telephone_interview_acceptable_code')\\\n",
    "    .join(df_bool, df_master.household_has_telephone_code == df_bool.bool_code, 'left')\\\n",
    "    .select(\n",
    "        col('bool_value').alias('household_has_telephone'),\n",
    "        'household_can_access_telephone_code',\n",
    "        'is_telephone_interview_acceptable_code',\n",
    "        )\n",
    "\n",
    "Question_3 = Question_3\\\n",
    "    .join(df_bool, df_master.household_can_access_telephone_code == df_bool.bool_code, 'left')\\\n",
    "    .select(\n",
    "        'household_has_telephone',\n",
    "        col('bool_value').alias('household_can_access_telephone'),\n",
    "        'is_telephone_interview_acceptable_code'\n",
    "        )\n",
    "\n",
    "Question_3 = Question_3\\\n",
    "    .join(df_bool, df_master.is_telephone_interview_acceptable_code == df_bool.bool_code, 'left')\\\n",
    "    .select(\n",
    "        'household_has_telephone',\n",
    "        'household_can_access_telephone',\n",
    "        col('bool_value').alias('is_telephone_interview_acceptable')\n",
    "        )\n",
    "\n",
    "#Question_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question_3.where(\n",
    "    (col('household_has_telephone') == lit('NO'  )) &\n",
    "    (col('household_can_access_telephone')  == lit('YES')) &\n",
    "    (col('is_telephone_interview_acceptable') == lit('YES'))\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The returned records count is: 635\n"
     ]
    }
   ],
   "source": [
    "cnt = df.where(\n",
    "        (col('household_has_telephone') == lit('NO')) & \n",
    "        (col('household_can_access_telephone')  == lit('YES')) &\n",
    "        (col('is_telephone_interview_acceptable') == lit('YES'))\n",
    "    ).count()\n",
    "\n",
    "if cnt == 0 :\n",
    "    print(f'There are no records returned.\\nThe returned value count is: {cnt}')\n",
    "else:\n",
    "    print(f'The returned records count is: {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(\n",
    "        (col('household_can_access_telephone')  == 'YES') &\n",
    "        (col('is_telephone_interview_acceptable') == 'NO')\n",
    "    ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24537"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.createOrReplaceTempView('master')\n",
    "spark.sql(\n",
    "    '''\n",
    "        select \n",
    "            household_can_access_telephone_code, \n",
    "            is_telephone_interview_acceptable_code\n",
    "        from master\n",
    "        where household_can_access_telephone_code = '1'\n",
    "        and is_telephone_interview_acceptable_code = '0'\n",
    "    '''\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-data-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
